{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98864f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n",
      "INFO:root:NCModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=1433, out_features=128, c=tensor([1.]))\n",
      "        (agg): HypAgg(c=tensor([1.]))\n",
      "        (hyp_act): HypAct(c_in=tensor([1.]), c_out=tensor([1.]))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): LinearDecoder(\n",
      "    in_features=128, out_features=7, bias=1, c=tensor([1.])\n",
      "    (cls): Linear(\n",
      "      (linear): Linear(in_features=128, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:root:Total number of parameters: 184455\n",
      "/Users/anoushkavyas/Downloads/GraphZoo/graphzoo/manifolds/poincare.py:99: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n",
      "  res = torch.where(cond, res_0, res_c)\n",
      "/Users/anoushkavyas/Downloads/GraphZoo/graphzoo/optimizers/radam.py:129: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  grad.add_(weight_decay, point)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0005 lr: 0.01 train_loss: 1.9502 train_acc: 0.1357 train_f1: 0.1357 time: 0.0786s\n",
      "INFO:root:Epoch: 0005 val_loss: 1.9459 val_acc: 0.1220 val_f1: 0.1220\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0010 lr: 0.01 train_loss: 1.9452 train_acc: 0.1429 train_f1: 0.1429 time: 0.0792s\n",
      "INFO:root:Epoch: 0010 val_loss: 1.9413 val_acc: 0.2080 val_f1: 0.2080\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0015 lr: 0.01 train_loss: 1.9369 train_acc: 0.1786 train_f1: 0.1786 time: 0.0793s\n",
      "INFO:root:Epoch: 0015 val_loss: 1.9355 val_acc: 0.3380 val_f1: 0.3380\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0020 lr: 0.01 train_loss: 1.9324 train_acc: 0.2071 train_f1: 0.2071 time: 0.0772s\n",
      "INFO:root:Epoch: 0020 val_loss: 1.9298 val_acc: 0.4000 val_f1: 0.4000\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0025 lr: 0.01 train_loss: 1.9325 train_acc: 0.1643 train_f1: 0.1643 time: 0.1211s\n",
      "INFO:root:Epoch: 0025 val_loss: 1.9255 val_acc: 0.4380 val_f1: 0.4380\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0030 lr: 0.01 train_loss: 1.9166 train_acc: 0.2929 train_f1: 0.2929 time: 0.0779s\n",
      "INFO:root:Epoch: 0030 val_loss: 1.9319 val_acc: 0.3240 val_f1: 0.3240\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0035 lr: 0.01 train_loss: 1.9021 train_acc: 0.3714 train_f1: 0.3714 time: 0.0864s\n",
      "INFO:root:Epoch: 0035 val_loss: 1.9280 val_acc: 0.3560 val_f1: 0.3560\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0040 lr: 0.01 train_loss: 1.8992 train_acc: 0.3143 train_f1: 0.3143 time: 0.0877s\n",
      "INFO:root:Epoch: 0040 val_loss: 1.9156 val_acc: 0.3860 val_f1: 0.3860\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0045 lr: 0.01 train_loss: 1.8713 train_acc: 0.3786 train_f1: 0.3786 time: 0.0872s\n",
      "INFO:root:Epoch: 0045 val_loss: 1.8957 val_acc: 0.4460 val_f1: 0.4460\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0050 lr: 0.01 train_loss: 1.8221 train_acc: 0.4643 train_f1: 0.4643 time: 0.0832s\n",
      "INFO:root:Epoch: 0050 val_loss: 1.8616 val_acc: 0.6200 val_f1: 0.6200\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0055 lr: 0.01 train_loss: 1.7787 train_acc: 0.4571 train_f1: 0.4571 time: 0.0833s\n",
      "INFO:root:Epoch: 0055 val_loss: 1.8159 val_acc: 0.6860 val_f1: 0.6860\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0060 lr: 0.01 train_loss: 1.6531 train_acc: 0.5286 train_f1: 0.5286 time: 0.0807s\n",
      "INFO:root:Epoch: 0060 val_loss: 1.7702 val_acc: 0.6420 val_f1: 0.6420\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0065 lr: 0.01 train_loss: 1.5985 train_acc: 0.5071 train_f1: 0.5071 time: 0.0837s\n",
      "INFO:root:Epoch: 0065 val_loss: 1.6990 val_acc: 0.6480 val_f1: 0.6480\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0070 lr: 0.01 train_loss: 1.5466 train_acc: 0.4429 train_f1: 0.4429 time: 0.0830s\n",
      "INFO:root:Epoch: 0070 val_loss: 1.5951 val_acc: 0.7120 val_f1: 0.7120\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0075 lr: 0.01 train_loss: 1.4144 train_acc: 0.4643 train_f1: 0.4643 time: 0.0833s\n",
      "INFO:root:Epoch: 0075 val_loss: 1.4814 val_acc: 0.7320 val_f1: 0.7320\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0080 lr: 0.01 train_loss: 1.2050 train_acc: 0.5429 train_f1: 0.5429 time: 0.0839s\n",
      "INFO:root:Epoch: 0080 val_loss: 1.3844 val_acc: 0.7580 val_f1: 0.7580\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0085 lr: 0.01 train_loss: 1.0766 train_acc: 0.5929 train_f1: 0.5929 time: 0.0824s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0085 val_loss: 1.2973 val_acc: 0.7320 val_f1: 0.7320\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0090 lr: 0.01 train_loss: 1.0608 train_acc: 0.6000 train_f1: 0.6000 time: 0.0830s\n",
      "INFO:root:Epoch: 0090 val_loss: 1.1859 val_acc: 0.7600 val_f1: 0.7600\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0095 lr: 0.01 train_loss: 1.0274 train_acc: 0.5929 train_f1: 0.5929 time: 0.0755s\n",
      "INFO:root:Epoch: 0095 val_loss: 1.0975 val_acc: 0.7600 val_f1: 0.7600\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0100 lr: 0.01 train_loss: 1.0268 train_acc: 0.5571 train_f1: 0.5571 time: 0.0758s\n",
      "INFO:root:Epoch: 0100 val_loss: 1.0431 val_acc: 0.7620 val_f1: 0.7620\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0105 lr: 0.01 train_loss: 0.9550 train_acc: 0.5786 train_f1: 0.5786 time: 0.0803s\n",
      "INFO:root:Epoch: 0105 val_loss: 1.0069 val_acc: 0.7620 val_f1: 0.7620\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0110 lr: 0.01 train_loss: 0.8248 train_acc: 0.6857 train_f1: 0.6857 time: 0.0766s\n",
      "INFO:root:Epoch: 0110 val_loss: 0.9624 val_acc: 0.7720 val_f1: 0.7720\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0115 lr: 0.01 train_loss: 0.9267 train_acc: 0.5929 train_f1: 0.5929 time: 0.0807s\n",
      "INFO:root:Epoch: 0115 val_loss: 0.9099 val_acc: 0.7900 val_f1: 0.7900\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0120 lr: 0.01 train_loss: 0.8288 train_acc: 0.6286 train_f1: 0.6286 time: 0.0829s\n",
      "INFO:root:Epoch: 0120 val_loss: 0.8945 val_acc: 0.7860 val_f1: 0.7860\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0125 lr: 0.01 train_loss: 0.7775 train_acc: 0.6571 train_f1: 0.6571 time: 0.0831s\n",
      "INFO:root:Epoch: 0125 val_loss: 0.8750 val_acc: 0.7740 val_f1: 0.7740\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0130 lr: 0.01 train_loss: 0.8289 train_acc: 0.5929 train_f1: 0.5929 time: 0.0795s\n",
      "INFO:root:Epoch: 0130 val_loss: 0.8505 val_acc: 0.7820 val_f1: 0.7820\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0135 lr: 0.01 train_loss: 0.7667 train_acc: 0.6429 train_f1: 0.6429 time: 0.0835s\n",
      "INFO:root:Epoch: 0135 val_loss: 0.8364 val_acc: 0.7840 val_f1: 0.7840\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0140 lr: 0.01 train_loss: 0.7771 train_acc: 0.6286 train_f1: 0.6286 time: 0.0860s\n",
      "INFO:root:Epoch: 0140 val_loss: 0.8180 val_acc: 0.7740 val_f1: 0.7740\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0145 lr: 0.01 train_loss: 0.7637 train_acc: 0.6071 train_f1: 0.6071 time: 0.0838s\n",
      "INFO:root:Epoch: 0145 val_loss: 0.8068 val_acc: 0.7680 val_f1: 0.7680\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0150 lr: 0.01 train_loss: 0.7700 train_acc: 0.6143 train_f1: 0.6143 time: 0.0790s\n",
      "INFO:root:Epoch: 0150 val_loss: 0.7986 val_acc: 0.7660 val_f1: 0.7660\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0155 lr: 0.01 train_loss: 0.7349 train_acc: 0.6357 train_f1: 0.6357 time: 0.0756s\n",
      "INFO:root:Epoch: 0155 val_loss: 0.7939 val_acc: 0.7700 val_f1: 0.7700\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0160 lr: 0.01 train_loss: 0.7033 train_acc: 0.6786 train_f1: 0.6786 time: 0.0796s\n",
      "INFO:root:Epoch: 0160 val_loss: 0.7926 val_acc: 0.7720 val_f1: 0.7720\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0165 lr: 0.01 train_loss: 0.7455 train_acc: 0.6357 train_f1: 0.6357 time: 0.0749s\n",
      "INFO:root:Epoch: 0165 val_loss: 0.7754 val_acc: 0.7720 val_f1: 0.7720\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0170 lr: 0.01 train_loss: 0.7003 train_acc: 0.7143 train_f1: 0.7143 time: 0.0747s\n",
      "INFO:root:Epoch: 0170 val_loss: 0.7709 val_acc: 0.7740 val_f1: 0.7740\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0175 lr: 0.01 train_loss: 0.7416 train_acc: 0.6286 train_f1: 0.6286 time: 0.0748s\n",
      "INFO:root:Epoch: 0175 val_loss: 0.7712 val_acc: 0.7700 val_f1: 0.7700\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0180 lr: 0.01 train_loss: 0.7009 train_acc: 0.6286 train_f1: 0.6286 time: 0.1083s\n",
      "INFO:root:Epoch: 0180 val_loss: 0.7746 val_acc: 0.7640 val_f1: 0.7640\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0185 lr: 0.01 train_loss: 0.7857 train_acc: 0.6000 train_f1: 0.6000 time: 0.0795s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0185 val_loss: 0.7805 val_acc: 0.7580 val_f1: 0.7580\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0190 lr: 0.01 train_loss: 0.7327 train_acc: 0.5786 train_f1: 0.5786 time: 0.0838s\n",
      "INFO:root:Epoch: 0190 val_loss: 0.7805 val_acc: 0.7740 val_f1: 0.7740\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0195 lr: 0.01 train_loss: 0.7899 train_acc: 0.6429 train_f1: 0.6429 time: 0.0789s\n",
      "INFO:root:Epoch: 0195 val_loss: 0.7808 val_acc: 0.7740 val_f1: 0.7740\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0200 lr: 0.01 train_loss: 0.8030 train_acc: 0.6214 train_f1: 0.6214 time: 0.0751s\n",
      "INFO:root:Epoch: 0200 val_loss: 0.7880 val_acc: 0.7740 val_f1: 0.7740\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0205 lr: 0.01 train_loss: 0.6979 train_acc: 0.6286 train_f1: 0.6286 time: 0.0745s\n",
      "INFO:root:Epoch: 0205 val_loss: 0.8028 val_acc: 0.7640 val_f1: 0.7640\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0210 lr: 0.01 train_loss: 0.6424 train_acc: 0.6643 train_f1: 0.6643 time: 0.0744s\n",
      "INFO:root:Epoch: 0210 val_loss: 0.8176 val_acc: 0.7460 val_f1: 0.7460\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "INFO:root:Epoch: 0215 lr: 0.01 train_loss: 0.7419 train_acc: 0.6286 train_f1: 0.6286 time: 0.0746s\n",
      "INFO:root:Epoch: 0215 val_loss: 0.8111 val_acc: 0.7520 val_f1: 0.7520\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 27.9948s\n",
      "INFO:root:Val set results: val_loss: 0.9099 val_acc: 0.7900 val_f1: 0.7900\n",
      "INFO:root:Test set results: test_loss: 0.8823 test_acc: 0.7880 test_f1: 0.7880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.8823, grad_fn=<NllLossBackward0>), 'acc': 0.788, 'f1': 0.788}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphzoo as gz\n",
    "import torch\n",
    "from graphzoo.config import parser\n",
    "\n",
    "#Defining Parameters\n",
    "params = parser.parse_args(args=[])\n",
    "\n",
    "#Preparing Data\n",
    "params.dataset='cora'\n",
    "params.datapath='data/cora'\n",
    "data = gz.dataloader.DataLoader(params)\n",
    "\n",
    "#Building Model\n",
    "params.task='lp'\n",
    "params.model='HGCN'\n",
    "params.manifold='PoincareBall'\n",
    "params.dim=128\n",
    "model= gz.models.LPModel(params)\n",
    "\n",
    "#Defining Optimizer\n",
    "optimizer = gz.optimizers.RiemannianAdam(params=model.parameters(), \n",
    "                                         lr=params.lr, weight_decay=params.weight_decay)\n",
    "\n",
    "#Training and Testing\n",
    "trainer=gz.trainers.Trainer(params,model,optimizer,data)\n",
    "trainer.run()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a154e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
